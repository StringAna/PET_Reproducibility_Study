%
% File proposal_template.tex
%
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2019}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}
\usepackage{enumitem} % Required for custom list spacing
\setlist[itemize]{itemsep=0em} % Applies to all itemize environments

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{Reproducing Pattern-Exploiting Training (PET): A Critical Analysis of Few-Shot Text Classification Using AG News Dataset}

\author{First Author \\
  Antara Tewary\\ 
  G01413546\\
  \texttt{atewary@gmu.edu} \\\And
  Second Author \\
  Ankit Kumar\\ 
  G01436204\\
  \texttt{akumar37@gmu.edu}\\\And
  Third Author \\
  Homa Haghighi\\ 
  G01145449\\
  \texttt{hhaghigh@gmu.edu}}

\date{}

\begin{document}
\maketitle

\section{Introduction}

The paper addresses the challenge of few-shot learning in NLP tasks, where only a small, labeled dataset is available. The research question is:\\
\textit{How can pre-trained language models (PLMs) like RoBERTa or BERT be adapted to excel at few-shot learning tasks using task-specific patterns and verbalizers? }\\
The paper's main goal is to explore whether reformulating inputs as cloze-style questions can improve performance on tasks such as text classification and natural language inference (NLI) under low-resource conditions. 
            \subsection{Task / Research Question Description} 
            Core research questions are-\\
            - Can natural language task descriptions be effectively combined with supervised learning to improve few-shot text classification?\\
            - How can we exploit the implicit knowledge in pre-trained language models through carefully designed patterns?\\
            - Is it possible to achieve better performance than standard supervised learning with as few as 10 labeled examples per class?
            \subsection{Motivation \& Limitations of existing work} 
            Existing few-shot learning methods often fail to effectively utilize pre-trained language models due to:
            \begin{itemize}[topsep=0pt]
              \item \textit{Lack of Task-Specific Adaptation}:Pre-trained models like BERT are not optimized for cloze-style tasks, which are effective for few-shot learning. 
              \item \textit{Heavy Dependence on Labeled Data}:Supervised models require large datasets, making them impractical for low-resource scenarios.
            \end{itemize} 
            The proposed approach (PET) addresses these issues by:
            \begin{itemize}[topsep=0pt]
              \item Exploiting task descriptions using patterns (templates) and verbalizers (label-to-word mappings). 
              \item Enhancing semi-supervised training through iterative refinement (iPET), which improves performance by gradually increasing labeled data. 
            \end{itemize}
            \subsection{Proposed Approach} 
            The core contribution is the Pattern-Exploiting Training (PET) framework: 
            \begin{itemize}[topsep=0pt]
              \setlength\itemsep{0em}
              \item \textit{Pattern and Verbalizer Design}:Reformulates tasks into cloze-style questions, enabling PLMs to better leverage their pre-training knowledge. 
              \item \textit{Soft Labeling}: Uses the model to annotate unlabeled data with probabilities (soft labels) to augment the training set.
              \item \textit{iPET}: An iterative method that refines the labeled dataset over multiple training cycles, leading to improved generalization. 
            \end{itemize}
            This approach enables few-shot learning by effectively combining human-readable patterns with the capabilities of large pre-trained models. 
            \subsection{Likely challenges and mitigations}
            \begin{itemize}
              \item \textit{Computational Resources}\\Challenge: Training large models demands significant GPU power.
              \\Mitigation:Start with smaller models and subsets of patterns; use gradient accumulation.
              \item \textit{Implementation Complexity}\\Challenge:Multi-stage training with intricate interactions.\\
              Mitigation: Modular design, extensive testing, and single-pattern trials.
            \end{itemize}


\section{Related Work}
Include 3-4 sentence descriptions of no less than 4 relevant papers (as applicable). Also mention how your work differs from these. Note that prior work should be properly cited in References, e.g., when you use the BERT model \cite{devlin2019bert} you could cite it in this way; if you want to refer to the authors of a certain paper, you should use \texttt{citet}, e.g., "\citet{devlin2019bert} proposed the BERT model." See \url{https://acl-org.github.io/ACLPUB/formatting.html} for instructions.
\begin{itemize}
  \item GPT-3 Few-Shot Learning Brown et al., \textit{"Language Models are Few-Shot Learners"}:This paper demonstrates the ability of GPT-3 to perform few-shot tasks using prompt-based learning. Unlike PET, it does not require task-specific fine-tuning, relying entirely on model size and carefully designed prompts. PET differs by using task-specific patterns and fine-tuning for better performance in low-resource settings. 
  \item T5 Model Raffel et al., \textit{"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}:T5 frames every NLP task as a text-to-text problem. While versatile, it requires fine-tuning on large datasets. PET, in contrast, uses minimal labeled data and focuses on few-shot performance. 
  \item Meta-Learning Approaches,\textit{Finn et al., "Model-Agnostic Meta-Learning (MAML)"}: MAML trains models to adapt quickly to new tasks with few examples. PET achieves similar goals using patterns and verbalizers, avoiding the need for gradient-based task adaptation.PET differs and uniquely leverages cloze-style questions and semi-supervised learning to combine task-specific insights with pre-trained models, making it more interpretable and efficient for few-shot tasks. 
\end{itemize}

\section{Experiments}

\subsection{Datasets}
Please list which datasets you used, whether or not you have access them, and whether or not they are publicly available with the same preprocessing and train / dev / tests as the previous work you will be comparing to (if applicable). If you plan to collect your own dataset for evaluating robustness, please describe clearly the data plan (the data source, how you plan to collect it, how you would preprocess it for the task, etc.).

\subsection{Implementation} 
Please provide a link to a repo of your reimplementation (if applicable) and appropriately cite any resources you have used.

\subsection{Results}
Provide a table comparing your results to the published results.

\subsection{Discussion}
Discuss any issues you faced. Do your results differ from the published ones? If yes, why do you think that is? Did you do a sensitivity analysis (e.g. multiple runs with different random seeds)?

\subsection{Resources}
Discuss the cost of your reproduction in terms of resources: computation, time, people, development effort, communication with the authors (if applicable).


\subsection{Error Analysis}
Perform an error analysis on the model. Include at least 2-3 instances where the model fails. Discuss the error analysis in the paper -- what other analyses could the authors have ran? If you were able to perform additional error analyses, report it here.

\section{Robustness Study}
Explain your approach for Evaluating the Model Robustness. Describe what robustness analysis you have performed. Provide sufficient details about your perturbation data, how you created it, how you used it as a robustness benchmark to evaluate the model, in what metrics, etc.

\subsection{Results of Robustness Evaluation}
Describe the evaluation results of your reproduced model on the robustness benchmark that you created. Include at least 2 examples where the model performs well and 2 examples where it fails (i.e., being not robust). Provide sufficient analysis and your thoughts on the observations.

\subsection{Discussion} 
Provide any further discussion here, e.g., what challenges did you face when performing the analysis, and what could have been done if you will have more time on this project? Imagine you are writing this report to future researchers; be sure to include "generalizable insights" (e.g., broadly speaking, any tips or advice you'd like to share for researchers trying to analyze the robustness of an NLP model).

\section{Workload Clarification}
Describe how  the team divides the workload in this checkpoint. Note that each team member should contribute roughly the same amount of work to this assignment.

\section{Conclusion}
Is the paper reproducible?

% \section{Credits}

% This document has been adapted from the instructions
% for earlier ACL and NAACL proceedings,
% including 
% those for 
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya, 
% ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu, 
% NAACL 2018 by Margaret Michell and Stephanie Lukin,
% 2017/2018 (NA)ACL bibtex suggestions from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan, 
% NAACL 2017 by Margaret Mitchell, 
% ACL 2012 by Maggie Li and Michael White, 
% those from ACL 2010 by Jing-Shing Chang and Philipp Koehn, 
% those for ACL 2008 by JohannaD. Moore, Simone Teufel, James Allan, and Sadaoki Furui, 
% those for ACL 2005 by Hwee Tou Ng and Kemal Oflazer, 
% those for ACL 2002 by Eugene Charniak and Dekang Lin, 
% and earlier ACL and EACL formats.
% Those versions were written by several
% people, including John Chen, Henry S. Thompson and Donald
% Walker. Additional elements were taken from the formatting
% instructions of the \emph{International Joint Conference on Artificial
%   Intelligence} and the \emph{Conference on Computer Vision and
%   Pattern Recognition}.

\bibliographystyle{acl_natbib} % We choose the "plain" reference style
\bibliography{refs} % Entries are in the refs.bib file

\end{document}
